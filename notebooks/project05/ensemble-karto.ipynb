{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b0a198c",
   "metadata": {},
   "source": [
    "# Project 5 — Ensemble Models (Wine Quality & Spiral)\n",
    "**Author:** Womenker Karto  \n",
    "**Date:** 2025-11-21\n",
    "\n",
    "**Overview:**  \n",
    "This notebook implements and compares ensemble classifiers on the UCI Wine Quality (red) dataset. I convert the quality score to three classes (low / medium / high) and evaluate multiple ensemble methods. I also load a secondary `spiral.csv` for optional exploration and visualization used in the lab example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068d03f6",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9006b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    BaggingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from typing import List, Dict\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963f8e28",
   "metadata": {},
   "source": [
    "## Section 1 — Load and Inspect the Data\n",
    "Load `winequality-red.csv` and `spiral.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b824fc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wine dataset shape: (1599, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fixed acidity</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>8.319637</td>\n",
       "      <td>1.741096</td>\n",
       "      <td>4.60000</td>\n",
       "      <td>7.1000</td>\n",
       "      <td>7.90000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>15.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volatile acidity</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.12000</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.52000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>1.58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citric acid</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residual sugar</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>1.9000</td>\n",
       "      <td>2.20000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>15.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chlorides</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>0.01200</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.07900</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.61100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>72.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>38.00000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>289.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.99007</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>0.99675</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>1.00369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pH</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>2.74000</td>\n",
       "      <td>3.2100</td>\n",
       "      <td>3.31000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>4.01000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sulphates</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>0.33000</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.62000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alcohol</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>8.40000</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>10.20000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>14.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>5.636023</td>\n",
       "      <td>0.807569</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count       mean        std      min      25%  \\\n",
       "fixed acidity         1599.0   8.319637   1.741096  4.60000   7.1000   \n",
       "volatile acidity      1599.0   0.527821   0.179060  0.12000   0.3900   \n",
       "citric acid           1599.0   0.270976   0.194801  0.00000   0.0900   \n",
       "residual sugar        1599.0   2.538806   1.409928  0.90000   1.9000   \n",
       "chlorides             1599.0   0.087467   0.047065  0.01200   0.0700   \n",
       "free sulfur dioxide   1599.0  15.874922  10.460157  1.00000   7.0000   \n",
       "total sulfur dioxide  1599.0  46.467792  32.895324  6.00000  22.0000   \n",
       "density               1599.0   0.996747   0.001887  0.99007   0.9956   \n",
       "pH                    1599.0   3.311113   0.154386  2.74000   3.2100   \n",
       "sulphates             1599.0   0.658149   0.169507  0.33000   0.5500   \n",
       "alcohol               1599.0  10.422983   1.065668  8.40000   9.5000   \n",
       "quality               1599.0   5.636023   0.807569  3.00000   5.0000   \n",
       "\n",
       "                           50%        75%        max  \n",
       "fixed acidity          7.90000   9.200000   15.90000  \n",
       "volatile acidity       0.52000   0.640000    1.58000  \n",
       "citric acid            0.26000   0.420000    1.00000  \n",
       "residual sugar         2.20000   2.600000   15.50000  \n",
       "chlorides              0.07900   0.090000    0.61100  \n",
       "free sulfur dioxide   14.00000  21.000000   72.00000  \n",
       "total sulfur dioxide  38.00000  62.000000  289.00000  \n",
       "density                0.99675   0.997835    1.00369  \n",
       "pH                     3.31000   3.400000    4.01000  \n",
       "sulphates              0.62000   0.730000    2.00000  \n",
       "alcohol               10.20000  11.100000   14.90000  \n",
       "quality                6.00000   6.000000    8.00000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"winequality-red.csv\", sep=\";\")\n",
    "print(\"Wine dataset shape:\", df.shape)\n",
    "display(df.head())\n",
    "display(df.describe().T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "685af927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spiral dataset shape: (798, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.912030</td>\n",
       "      <td>-1.108531</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.663918</td>\n",
       "      <td>2.714674</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.481765</td>\n",
       "      <td>0.088643</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.839247</td>\n",
       "      <td>3.163379</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.915366</td>\n",
       "      <td>-0.939925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B  Class\n",
       "0  3.912030 -1.108531      0\n",
       "1  2.663918  2.714674      0\n",
       "2  0.481765  0.088643      0\n",
       "3 -0.839247  3.163379      0\n",
       "4  3.915366 -0.939925      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spiral = pd.read_csv(\"spiral.csv\", sep=\"\\t\")\n",
    "print(\"Spiral dataset shape:\", spiral.shape)\n",
    "display(spiral.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc02653",
   "metadata": {},
   "source": [
    "## Section 2 — Prepare the Data\n",
    "Create categorical labels (low/medium/high) and a numeric target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f586ba3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution (labels):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "quality_label\n",
       "medium    1319\n",
       "high       217\n",
       "low         63\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numeric distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "quality_numeric\n",
       "1    1319\n",
       "2     217\n",
       "0      63\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def quality_to_label(q: int) -> str:\n",
    "    if q <= 4:\n",
    "        return \"low\"\n",
    "    elif q <= 6:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"high\"\n",
    "\n",
    "def quality_to_number(q: int) -> int:\n",
    "    if q <= 4:\n",
    "        return 0\n",
    "    elif q <= 6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df[\"quality_label\"] = df[\"quality\"].apply(quality_to_label)\n",
    "df[\"quality_numeric\"] = df[\"quality\"].apply(quality_to_number)\n",
    "\n",
    "print(\"Class distribution (labels):\")\n",
    "display(df[\"quality_label\"].value_counts())\n",
    "print(\"\\nNumeric distribution:\")\n",
    "display(df[\"quality_numeric\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6136586d",
   "metadata": {},
   "source": [
    "## Section 3 — Feature Selection and Justification\n",
    "Use the 11 physicochemical features as input X and `quality_numeric` as target y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0876b0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature set shape: (1599, 11)\n",
      "Target value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "quality_numeric\n",
       "1    1319\n",
       "2     217\n",
       "0      63\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = df.drop(columns=[\"quality\", \"quality_label\", \"quality_numeric\"])\n",
    "y = df[\"quality_numeric\"]\n",
    "print(\"Feature set shape:\", X.shape)\n",
    "print(\"Target value counts:\")\n",
    "display(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db07ae0",
   "metadata": {},
   "source": [
    "## Section 4 — Split the Data into Train and Test\n",
    "We use a stratified split to preserve class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e3750a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1279, 11) Test shape: (320, 11)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc102d8",
   "metadata": {},
   "source": [
    "## Section 5 — Evaluate Model Performance\n",
    "We will run a set of ensemble models and record Train/Test accuracy, Train/Test F1, and gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "44516c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name: str, model, X_tr, y_tr, X_te, y_te, results: List[Dict], use_scaled: bool = False,\n",
    "                   scaler: StandardScaler = None):\n",
    "    # Optionally scale inputs (for SVM / MLP / models that benefited from scaling)\n",
    "    if use_scaled and scaler is not None:\n",
    "        X_tr_used = scaler.transform(X_tr)\n",
    "        X_te_used = scaler.transform(X_te)\n",
    "    else:\n",
    "        X_tr_used = X_tr\n",
    "        X_te_used = X_te\n",
    "\n",
    "    model.fit(X_tr_used, y_tr)\n",
    "    y_train_pred = model.predict(X_tr_used)\n",
    "    y_test_pred = model.predict(X_te_used)\n",
    "\n",
    "    train_acc = accuracy_score(y_tr, y_train_pred)\n",
    "    test_acc = accuracy_score(y_te, y_test_pred)\n",
    "    train_f1 = f1_score(y_tr, y_train_pred, average=\"weighted\")\n",
    "    test_f1 = f1_score(y_te, y_test_pred, average=\"weighted\")\n",
    "\n",
    "    print(f\"\\n{name} Results\")\n",
    "    print(\"Confusion Matrix (Test):\")\n",
    "    print(confusion_matrix(y_te, y_test_pred))\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Train F1 Score: {train_f1:.4f}, Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Train Accuracy\": train_acc,\n",
    "        \"Test Accuracy\": test_acc,\n",
    "        \"Train F1\": train_f1,\n",
    "        \"Test F1\": test_f1,\n",
    "        \"Train-Test Acc Gap\": round(train_acc - test_acc, 4),\n",
    "        \"Train-Test F1 Gap\": round(train_f1 - test_f1, 4),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a6a6ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f3a094b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest (100) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  0 256   8]\n",
      " [  0  15  28]]\n",
      "Train Accuracy: 1.0000, Test Accuracy: 0.8875\n",
      "Train F1 Score: 1.0000, Test F1 Score: 0.8661\n",
      "\n",
      "Random Forest (200, max_depth=10) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  0 255   9]\n",
      " [  0  16  27]]\n",
      "Train Accuracy: 0.9758, Test Accuracy: 0.8812\n",
      "Train F1 Score: 0.9745, Test F1 Score: 0.8596\n",
      "\n",
      "AdaBoost (100) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  2  11   0]\n",
      " [  8 214  42]\n",
      " [  0  15  28]]\n",
      "Train Accuracy: 0.7834, Test Accuracy: 0.7625\n",
      "Train F1 Score: 0.7958, Test F1 Score: 0.7743\n",
      "\n",
      "AdaBoost (200, lr=0.5) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  1  12   0]\n",
      " [  7 228  29]\n",
      " [  0  18  25]]\n",
      "Train Accuracy: 0.8038, Test Accuracy: 0.7937\n",
      "Train F1 Score: 0.8071, Test F1 Score: 0.7938\n",
      "\n",
      "Gradient Boosting (100) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  3 247  14]\n",
      " [  0  16  27]]\n",
      "Train Accuracy: 0.9601, Test Accuracy: 0.8562\n",
      "Train F1 Score: 0.9584, Test F1 Score: 0.8411\n",
      "\n",
      "Voting (DT + SVM + NN) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  1 250  13]\n",
      " [  0  14  29]]\n",
      "Train Accuracy: 0.9664, Test Accuracy: 0.8719\n",
      "Train F1 Score: 0.9647, Test F1 Score: 0.8542\n",
      "\n",
      "Voting (RF + LR + KNN) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  0 258   6]\n",
      " [  0  26  17]]\n",
      "Train Accuracy: 0.9187, Test Accuracy: 0.8594\n",
      "Train F1 Score: 0.9012, Test F1 Score: 0.8280\n",
      "\n",
      "Bagging (DT, 100) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  0 252  12]\n",
      " [  0  12  31]]\n",
      "Train Accuracy: 1.0000, Test Accuracy: 0.8844\n",
      "Train F1 Score: 1.0000, Test F1 Score: 0.8655\n",
      "\n",
      "MLP Classifier Results\n",
      "Confusion Matrix (Test):\n",
      "[[  2  11   0]\n",
      " [  5 240  19]\n",
      " [  0  13  30]]\n",
      "Train Accuracy: 0.9711, Test Accuracy: 0.8500\n",
      "Train F1 Score: 0.9700, Test F1 Score: 0.8458\n"
     ]
    }
   ],
   "source": [
    "# Run the chosen ensemble models (I run all 9 for comparison)\n",
    "results = []\n",
    "\n",
    "# 1. Random Forest (100)\n",
    "evaluate_model(\n",
    "    \"Random Forest (100)\",\n",
    "    RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE),\n",
    "    X_train, y_train, X_test, y_test, results\n",
    ")\n",
    "\n",
    "# 2. Random Forest (200, max_depth=10)\n",
    "evaluate_model(\n",
    "    \"Random Forest (200, max_depth=10)\",\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=10, random_state=RANDOM_STATE),\n",
    "    X_train, y_train, X_test, y_test, results\n",
    ")\n",
    "\n",
    "# 3. AdaBoost (100)\n",
    "evaluate_model(\n",
    "    \"AdaBoost (100)\",\n",
    "    AdaBoostClassifier(n_estimators=100, random_state=RANDOM_STATE),\n",
    "    X_train, y_train, X_test, y_test, results\n",
    ")\n",
    "\n",
    "# 4. AdaBoost (200, lr=0.5)\n",
    "evaluate_model(\n",
    "    \"AdaBoost (200, lr=0.5)\",\n",
    "    AdaBoostClassifier(n_estimators=200, learning_rate=0.5, random_state=RANDOM_STATE),\n",
    "    X_train, y_train, X_test, y_test, results\n",
    ")\n",
    "\n",
    "# 5. Gradient Boosting (100)\n",
    "evaluate_model(\n",
    "    \"Gradient Boosting (100)\",\n",
    "    GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=RANDOM_STATE),\n",
    "    X_train, y_train, X_test, y_test, results\n",
    ")\n",
    "\n",
    "# 6. Voting (DT + SVM + NN) - use scaled inputs for SVM and NN\n",
    "voting1 = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"DT\", DecisionTreeClassifier(random_state=RANDOM_STATE)),\n",
    "        (\"SVM\", SVC(probability=True, random_state=RANDOM_STATE)),\n",
    "        (\"NN\", MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000, random_state=RANDOM_STATE)),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    ")\n",
    "# We will train voting1 on scaled arrays\n",
    "evaluate_model(\"Voting (DT + SVM + NN)\", voting1, X_train, y_train, X_test, y_test, results, use_scaled=True, scaler=scaler)\n",
    "\n",
    "# 7. Voting (RF + LR + KNN)\n",
    "voting2 = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"RF\", RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)),\n",
    "        (\"LR\", LogisticRegression(max_iter=1000, random_state=RANDOM_STATE)),\n",
    "        (\"KNN\", KNeighborsClassifier()),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    ")\n",
    "evaluate_model(\"Voting (RF + LR + KNN)\", voting2, X_train, y_train, X_test, y_test, results)\n",
    "\n",
    "# 8. Bagging (DT, 100)\n",
    "evaluate_model(\n",
    "    \"Bagging (DT, 100)\",\n",
    "    BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=RANDOM_STATE),\n",
    "    X_train, y_train, X_test, y_test, results\n",
    ")\n",
    "\n",
    "# 9. MLP Classifier (use scaled)\n",
    "evaluate_model(\n",
    "    \"MLP Classifier\",\n",
    "    MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=RANDOM_STATE),\n",
    "    X_train, y_train, X_test, y_test, results, use_scaled=True, scaler=scaler\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc3b363",
   "metadata": {},
   "source": [
    "## Section 6 — Compare Results\n",
    "Create a DataFrame from `results`, compute gaps (already included), sort by Test Accuracy, and save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90529002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Test F1</th>\n",
       "      <th>Train-Test Acc Gap</th>\n",
       "      <th>Train-Test F1 Gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest (100)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866056</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.1339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bagging (DT, 100)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865452</td>\n",
       "      <td>0.1156</td>\n",
       "      <td>0.1345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest (200, max_depth=10)</td>\n",
       "      <td>0.975762</td>\n",
       "      <td>0.881250</td>\n",
       "      <td>0.974482</td>\n",
       "      <td>0.859643</td>\n",
       "      <td>0.0945</td>\n",
       "      <td>0.1148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting (DT + SVM + NN)</td>\n",
       "      <td>0.966380</td>\n",
       "      <td>0.871875</td>\n",
       "      <td>0.964747</td>\n",
       "      <td>0.854168</td>\n",
       "      <td>0.0945</td>\n",
       "      <td>0.1106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Voting (RF + LR + KNN)</td>\n",
       "      <td>0.918686</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.901189</td>\n",
       "      <td>0.828047</td>\n",
       "      <td>0.0593</td>\n",
       "      <td>0.0731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boosting (100)</td>\n",
       "      <td>0.960125</td>\n",
       "      <td>0.856250</td>\n",
       "      <td>0.958410</td>\n",
       "      <td>0.841106</td>\n",
       "      <td>0.1039</td>\n",
       "      <td>0.1173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP Classifier</td>\n",
       "      <td>0.971071</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.969991</td>\n",
       "      <td>0.845761</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>0.1242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost (200, lr=0.5)</td>\n",
       "      <td>0.803753</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.807132</td>\n",
       "      <td>0.793824</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost (100)</td>\n",
       "      <td>0.783425</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.795827</td>\n",
       "      <td>0.774253</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.0216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Model  Train Accuracy  Test Accuracy  Train F1  \\\n",
       "0                Random Forest (100)        1.000000       0.887500  1.000000   \n",
       "1                  Bagging (DT, 100)        1.000000       0.884375  1.000000   \n",
       "2  Random Forest (200, max_depth=10)        0.975762       0.881250  0.974482   \n",
       "3             Voting (DT + SVM + NN)        0.966380       0.871875  0.964747   \n",
       "4             Voting (RF + LR + KNN)        0.918686       0.859375  0.901189   \n",
       "5            Gradient Boosting (100)        0.960125       0.856250  0.958410   \n",
       "6                     MLP Classifier        0.971071       0.850000  0.969991   \n",
       "7             AdaBoost (200, lr=0.5)        0.803753       0.793750  0.807132   \n",
       "8                     AdaBoost (100)        0.783425       0.762500  0.795827   \n",
       "\n",
       "    Test F1  Train-Test Acc Gap  Train-Test F1 Gap  \n",
       "0  0.866056              0.1125             0.1339  \n",
       "1  0.865452              0.1156             0.1345  \n",
       "2  0.859643              0.0945             0.1148  \n",
       "3  0.854168              0.0945             0.1106  \n",
       "4  0.828047              0.0593             0.0731  \n",
       "5  0.841106              0.1039             0.1173  \n",
       "6  0.845761              0.1211             0.1242  \n",
       "7  0.793824              0.0100             0.0133  \n",
       "8  0.774253              0.0209             0.0216  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ensemble_results_summary.csv\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df_sorted = results_df.sort_values(by=\"Test Accuracy\", ascending=False).reset_index(drop=True)\n",
    "display(results_df_sorted)\n",
    "results_df_sorted.to_csv(\"ensemble_results_summary.csv\", index=False)\n",
    "print(\"Saved ensemble_results_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29254c62",
   "metadata": {},
   "source": [
    "## Section 7 — Conclusions and Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7480cf",
   "metadata": {},
   "source": [
    "- **Overall Model Performance:** \n",
    "    After evaluating nine ensemble and advanced models on the Wine Quality dataset, several clear patterns emerged. The strongest performers based on test accuracy and test F1 score were:\n",
    "    - **Random Forest (100)** – Test Accuracy: 0.8875 | Test F1: 0.8661\n",
    "    - **Bagging (DT, 100)** – Test Accuracy: 0.8844 | Test F1: 0.8655\n",
    "    - **Random Forest (200, max_depth=10)** – Test Accuracy: 0.8813 | Test F1: 0.8596\n",
    "\n",
    "    These models consistently showed strong predictive power while maintaining relatively controlled gaps between training and testing performance.\n",
    "\n",
    "    The top performer overall was **Random Forest (100)**, which achieved the highest test accuracy and F1 score. However, it also showed a noticeable train-test gap, indicating some degree of overfitting, though still within an acceptable range for ensemble models. \n",
    "\n",
    "- **Observations on Model Types:** \n",
    "    - **Ensemble tree-based methods (Random Forest & Bagging)** performed best overall. This aligns with expectations, as these methods excel at capturing non-linear relationships and reducing variance through aggregation.\n",
    "    - **Boosting models (AdaBoost)** showed the lowest performance but had very small gaps, indicating stable generalization but limited learning capacity for this dataset.\n",
    "    - **Voting classifiers** demonstrated good balance, particularly when diverse model types were combined.\n",
    "    - **MLP Classifier** performed reasonably well but showed signs of overfitting, as indicated by its larger train-test gap."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
